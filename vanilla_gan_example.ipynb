{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               video\n",
      "0  [[/Users/jesusnavarro/Desktop/gan_video/UAV123...\n",
      "1  [[/Users/jesusnavarro/Desktop/gan_video/UAV123...\n",
      "2  [[/Users/jesusnavarro/Desktop/gan_video/UAV123...\n",
      "3  [[/Users/jesusnavarro/Desktop/gan_video/UAV123...\n",
      "4  [[/Users/jesusnavarro/Desktop/gan_video/UAV123...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2e68a6dfa17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mreal_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mreal_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mreal_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "# %load '/Users/jesusnavarro/Desktop/gan_video/core/main.py'\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.autograd\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import logging\n",
    "from core.model import *\n",
    "from core.UAVDataset import *\n",
    "\n",
    "def setup_logger(logger_name):\n",
    "    # format string\n",
    "    LOG_FORMAT = \"%(levelname)s - %(asctime)s - %(messages)s\"\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    \n",
    "    # create formatter\n",
    "    formatter = logging.Formatter(fmt=LOG_FORMAT)\n",
    "    \n",
    "    # create handler, streamhandler, and format\n",
    "    file_handler = logging.FileHandler('training_log.txt', mode='w')\n",
    "    file_handler.setFormatter(file_handler)\n",
    "    screen_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    screen_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(screen_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def save_image(img, filename):\n",
    "    img = img.detach()\n",
    "    pil_img = ToPILImage()\n",
    "    img = pil_img(img)\n",
    "    img.save(filename)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    num_epochs = 30\n",
    "    num_batch = 5\n",
    "    \n",
    "    # Create binary cross entropy function\n",
    "    loss = torch.nn.BCELoss()\n",
    "    batch_size = 5\n",
    "    \n",
    "    # Define transforms to apply to the data\n",
    "    composed = transforms.Compose([Rescale(64), ToTensor()])\n",
    "    \n",
    "    # Define location of data pickle files\n",
    "    # Batches of 32 sequential frame paths are grouped together in a pandas df\n",
    "    working_dir = %pwd\n",
    "    sub_dir = '/pickle_data/test_200_videos.pickle'\n",
    "    \n",
    "    # Instantiate DataLoader object\n",
    "    transformed_uav_dataset = UAVDataset(pickle_path= working_dir + sub_dir,\n",
    "                                         transform=composed)\n",
    "    data_loader = DataLoader(transformed_uav_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "    num_batches = len(data_loader)\n",
    "    \n",
    "    # Instantiate generator and discriminator\n",
    "    generator = VideoGen().float()\n",
    "    discriminator = VideoDiscriminator().float()\n",
    "    \n",
    "    # Directory to save generator videos\n",
    "    DIR_TO_SAVE = \"./gen_videos/\"\n",
    "    if not os.path.exists(DIR_TO_SAVE):\n",
    "        os.makedirs(DIR_TO_SAVE)\n",
    "    sample_input = None\n",
    "    sample_input_set = False\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Define optimizer for the discriminator and generator\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.002)\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.002)\n",
    "\n",
    "    for eopch in range(num_epochs):\n",
    "\n",
    "        for (iter_num, batch) in enumerate(data_loader):\n",
    "            # reset gradients\n",
    "            generator.zero_grad()\n",
    "            discriminator.zero_grad()\n",
    "            \n",
    "            real_video = batch['video'] \n",
    "            real_video = real_video.unsqueeze(0).repeat(1, 1, 1, 1, 1)\n",
    "            real_video = real_video.permute(0,2,1,3,4)\n",
    "            \n",
    "            real_labels = torch.tensor(np.ones(1, real_video.size(0)))\n",
    "            fake_labels = torch.tensor(np.zeros(1, real_video.size()))\n",
    "            \n",
    "            if not iter_num % 3 == 0: # Train discriminator\n",
    "                r_real_output = discriminator(real_video).squeeze()\n",
    "                \n",
    "                # Generate a fake video, detach parameters\n",
    "                latent_z = torch.randn(1, 1, 1, 1, 100)\n",
    "                fake_video = generator(latent_z).squeeze().detach()\n",
    "                d_fake_output = discriminator(fake_video)\n",
    "                \n",
    "                # Compute real and fake loss\n",
    "                d_fake_loss = loss_function(d_fake_output, fake_labels)\n",
    "                d_real_loss = loss_function(d_real_output, real_labels)\n",
    "                d_loss = d_real_loss + d_fake_loss\n",
    "                \n",
    "                # Update Gradient\n",
    "                d_loss.backward()\n",
    "                d_optimizer.step()\n",
    "                \n",
    "            else: # Train generator\n",
    "                first_frame = real_video[:,:,0:1,:,:]\n",
    "                latent_z = torch.randn(1,1,1,N,100)\n",
    "                fake_videos = generator(latent_z)\n",
    "                d_fake_outputs = discriminator(fake_videos).squeeze()\n",
    "                gen_first_frame = fake_videos[:,:,0:1,:,:]\n",
    "                reg_loss = torch.mean(torch.abs(first_frame - gen_first_frame)) * l1_lambda\n",
    "                g_loss = loss_function(outputs, real_labels) + reg_loss\n",
    "                g_loss.backward()\n",
    "                g_optimizer.step()\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jesusnavarro/Desktop/gan_video'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
